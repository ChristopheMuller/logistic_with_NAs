pred_y <- pred_y[,1]
}
bayes_y_file <- file.path("data", exp, "bayes_data", paste0(setup, ".npz"))
bayes <- np$load(bayes_y_file)
bayes_y <- bayes$f[["y_probs_bayes"]]
diag <- reliabilitydiag(preds = pred_y, bayes=bayes_y, y = y_test)
cali <- summary(diag)$miscalibration
pred_score <- cali[1]
pred_bayes <- cali[2]
# add score to matrix
new_row <- c(exp, setup, method, ntrain, FALSE, "calibration", pred_score, "all")
new_row_bayes <- c(exp, setup, method, ntrain, TRUE, "calibration", pred_score-pred_bayes, "all")
matrix_scores <- rbind(matrix_scores, new_row)
matrix_scores <- rbind(matrix_scores, new_row_bayes)
}
}
source("methods_in_R.R")
set.seed(123) # for reproducibility
X_dummy <- data.frame(
feat1 = rnorm(100),
feat2 = rnorm(100),
feat3 = rnorm(100)
)
# Dummy missingness mask (M)
# 0 = observed, 1 = missing (as per your Python example)
M_dummy <- matrix(0, nrow = 100, ncol = 3)
# Introduce some missing patterns:
# Pattern 1: All observed (0_0_0) - should be 70% of data
# Pattern 2: feat2 missing (0_1_0) - should be 20% of data
M_dummy[71:90, 2] <- 1
# Pattern 3: feat1 and feat3 missing (1_0_1) - should be 10% of data
M_dummy[91:100, 1] <- 1
M_dummy[91:100, 3] <- 1
# Create NAs in X based on M
X_dummy_with_na <- X_dummy
for (r in 1:nrow(M_dummy)) {
for (c in 1:ncol(M_dummy)) {
if (M_dummy[r, c] == 1) {
X_dummy_with_na[r, c] <- NA
}
}
}
X_dummy_with_na
y_dummy <- as.numeric(X_dummy$feat1 + X_dummy$feat2 + rnorm(100, 0, 0.5) > 0)
y_dummy
cat("Dummy data created:\n")
cat("  X (with NAs) dimensions:", dim(X_dummy_with_na), "\n")
cat("  M (mask) dimensions:", dim(M_dummy), "\n")
cat("  y (outcome) length:", length(y_dummy), "\n")
cat("\nSample of X (with NAs) and M:\n")
print(head(cbind(X_dummy_with_na, M_dummy)))
print(tail(cbind(X_dummy_with_na, M_dummy)))
cat("\nInstantiating and training RegLogPatByPat method...\n")
# Create an instance of your Pattern-by-Pattern method
pbp_method <- RegLogPatByPat$new(name = "MyPbPMethod")
X_dummy_with_na
M_dummy
y_dummy
# Fit the model using the dummy data
# This will train a separate glm for each unique pattern
fit_success <- pbp_method$fit(X = X_dummy_with_na, M = M_dummy, y = y_dummy)
args <- commandArgs(trailingOnly = TRUE)
source("methods_in_R.R")
cat("Creating dummy data...\n")
set.seed(123) # for reproducibility
X_dummy <- data.frame(
feat1 = rnorm(100),
feat2 = rnorm(100),
feat3 = rnorm(100)
)
# Dummy missingness mask (M)
# 0 = observed, 1 = missing (as per your Python example)
M_dummy <- matrix(0, nrow = 100, ncol = 3)
# Introduce some missing patterns:
# Pattern 1: All observed (0_0_0) - should be 70% of data
# Pattern 2: feat2 missing (0_1_0) - should be 20% of data
M_dummy[71:90, 2] <- 1
# Pattern 3: feat1 and feat3 missing (1_0_1) - should be 10% of data
M_dummy[91:100, 1] <- 1
M_dummy[91:100, 3] <- 1
# Create NAs in X based on M
X_dummy_with_na <- X_dummy
for (r in 1:nrow(M_dummy)) {
for (c in 1:ncol(M_dummy)) {
if (M_dummy[r, c] == 1) {
X_dummy_with_na[r, c] <- NA
}
}
}
y_dummy <- as.numeric(X_dummy$feat1 + X_dummy$feat2 + rnorm(100, 0, 0.5) > 0)
cat("Dummy data created:\n")
cat("  X (with NAs) dimensions:", dim(X_dummy_with_na), "\n")
cat("  M (mask) dimensions:", dim(M_dummy), "\n")
cat("  y (outcome) length:", length(y_dummy), "\n")
cat("\nSample of X (with NAs) and M:\n")
print(tail(cbind(X_dummy_with_na, M_dummy)))
cat("\nInstantiating and training RegLogPatByPat method...\n")
# Create an instance of your Pattern-by-Pattern method
pbp_method <- RegLogPatByPat$new(name = "MyPbPMethod")
# Fit the model using the dummy data
# This will train a separate glm for each unique pattern
fit_success <- pbp_method$fit(X = X_dummy_with_na, M = M_dummy, y = y_dummy)
source("methods_in_R.R")
cat("Creating dummy data...\n")
set.seed(123) # for reproducibility
X_dummy <- data.frame(
feat1 = rnorm(100),
feat2 = rnorm(100),
feat3 = rnorm(100)
)
# Dummy missingness mask (M)
# 0 = observed, 1 = missing (as per your Python example)
M_dummy <- matrix(0, nrow = 100, ncol = 3)
# Introduce some missing patterns:
# Pattern 1: All observed (0_0_0) - should be 70% of data
# Pattern 2: feat2 missing (0_1_0) - should be 20% of data
M_dummy[71:90, 2] <- 1
# Pattern 3: feat1 and feat3 missing (1_0_1) - should be 10% of data
M_dummy[91:100, 1] <- 1
M_dummy[91:100, 3] <- 1
# Create NAs in X based on M
X_dummy_with_na <- X_dummy
for (r in 1:nrow(M_dummy)) {
for (c in 1:ncol(M_dummy)) {
if (M_dummy[r, c] == 1) {
X_dummy_with_na[r, c] <- NA
}
}
}
y_dummy <- as.numeric(X_dummy$feat1 + X_dummy$feat2 + rnorm(100, 0, 0.5) > 0)
cat("Dummy data created:\n")
cat("  X (with NAs) dimensions:", dim(X_dummy_with_na), "\n")
cat("  M (mask) dimensions:", dim(M_dummy), "\n")
cat("  y (outcome) length:", length(y_dummy), "\n")
cat("\nSample of X (with NAs) and M:\n")
print(tail(cbind(X_dummy_with_na, M_dummy)))
# ---
# 3. Instantiate and train RegLogPatByPat
# ---
cat("\nInstantiating and training RegLogPatByPat method...\n")
# Create an instance of your Pattern-by-Pattern method
pbp_method <- RegLogPatByPat$new(name = "MyPbPMethod")
# Fit the model using the dummy data
# This will train a separate glm for each unique pattern
fit_success <- pbp_method$fit(X = X_dummy_with_na, M = M_dummy, y = y_dummy)
if (fit_success) {
cat("RegLogPatByPat fit successfully.\n")
cat("Number of models trained for unique patterns:", length(pbp_method$models_by_pattern), "\n")
# You can inspect the stored models:
# names(pbp_method$models_by_pattern)
# summary(pbp_method$models_by_pattern[["0_0_0"]]) # Example: for the all-observed pattern
} else {
cat("RegLogPatByPat fitting failed.\n")
}
pbp_method$models_by_pattern
pbp_method$models_by_pattern$`0_0_0`$formula
pbp_method$models_by_pattern$`1_0_1`$formula
cat("\nDemonstrating prediction...\n")
# Create some new dummy data for prediction
X_new_dummy <- data.frame(
feat1 = c(0.5, -1.0, 1.5, -0.5, 0.2),
feat2 = c(0.1, 0.8, -0.2, NA, NA), # Some NAs here
feat3 = c(-0.3, NA, 0.7, 0.4, NA)  # Some NAs here
)
# Create corresponding mask for new data
M_new_dummy <- matrix(0, nrow = nrow(X_new_dummy), ncol = ncol(X_new_dummy))
M_new_dummy[is.na(X_new_dummy)] <- 1 # Set 1 for NA, 0 for observed
cat("New data for prediction:\n")
print(X_new_dummy)
cat("\nNew data mask:\n")
print(M_new_dummy)
# Predict probabilities using the trained method
predicted_probs <- pbp_method$predict_probs(X_new = X_new_dummy, M_new = M_new_dummy)
cat("\nPredicted probabilities for new data:\n")
print(predicted_probs)
y_dummy
mean(y_dummy)
cat("\nScript finished successfully.\n")
# Now, source your actual methods file:
source("methods_in_R.R")
cat("Creating dummy data...\n")
# Now, source your actual methods file:
source("methods_in_R.R")
# Please ensure the path is correct or place this script in the same directory.
# ---
# 2. Create dummy data
# ---
cat("Creating dummy data...\n")
n<-5
# Dummy features (X)
set.seed(123) # for reproducibility
X_dummy <- data.frame(
feat1 = rnorm(n),
feat2 = rnorm(n),
feat3 = rnorm(n)
)
# Dummy missingness mask (M)
# 0 = observed, 1 = missing (as per your Python example)
M_dummy <- matrix(0, nrow = n, ncol = 3)
# Introduce some missing patterns:
# Pattern 1: All observed (0_0_0) - should be 70% of data
# Pattern 2: feat2 missing (0_1_0) - should be 20% of data
M_dummy[1, 2] <- 1
# Pattern 3: feat1 and feat3 missing (1_0_1) - should be 10% of data
M_dummy[2, 1] <- 1
M_dummy[3, 3] <- 1
# Create NAs in X based on M
X_dummy_with_na <- X_dummy
for (r in 1:nrow(M_dummy)) {
for (c in 1:ncol(M_dummy)) {
if (M_dummy[r, c] == 1) {
X_dummy_with_na[r, c] <- NA
}
}
}
# Dummy binary outcome (y)
# Let y depend on feat1 and feat2 (when observed)
y_dummy <- as.numeric(X_dummy$feat1 + X_dummy$feat2 + rnorm(n, 0, 0.5) > 0)
cat("Dummy data created:\n")
cat("  X (with NAs) dimensions:", dim(X_dummy_with_na), "\n")
cat("  M (mask) dimensions:", dim(M_dummy), "\n")
cat("  y (outcome) length:", length(y_dummy), "\n")
cat("\nSample of X (with NAs) and M:\n")
print(head(cbind(X_dummy_with_na, M_dummy)))
cat("\nInstantiating and training RegLogPatByPat method...\n")
y_dummy
cat("\nInstantiating and training RegLogPatByPat method...\n")
# Create an instance of your Pattern-by-Pattern method
pbp_method <- RegLogPatByPat$new(name = "MyPbPMethod")
# Fit the model using the dummy data
# This will train a separate glm for each unique pattern
fit_success <- pbp_method$fit(X = X_dummy_with_na, M = M_dummy, y = y_dummy)
if (fit_success) {
cat("RegLogPatByPat fit successfully.\n")
cat("Number of models trained for unique patterns:", length(pbp_method$models_by_pattern), "\n")
# You can inspect the stored models:
# names(pbp_method$models_by_pattern)
# summary(pbp_method$models_by_pattern[["0_0_0"]]) # Example: for the all-observed pattern
} else {
cat("RegLogPatByPat fitting failed.\n")
}
# Now, source your actual methods file:
source("methods_in_R.R")
# Please ensure the path is correct or place this script in the same directory.
# ---
# 2. Create dummy data
# ---
cat("Creating dummy data...\n")
n<-5
# Dummy features (X)
set.seed(123) # for reproducibility
X_dummy <- data.frame(
feat1 = rnorm(n),
feat2 = rnorm(n),
feat3 = rnorm(n)
)
# Dummy missingness mask (M)
# 0 = observed, 1 = missing (as per your Python example)
M_dummy <- matrix(0, nrow = n, ncol = 3)
# Create NAs in X based on M
X_dummy_with_na <- X_dummy
for (r in 1:nrow(M_dummy)) {
for (c in 1:ncol(M_dummy)) {
if (M_dummy[r, c] == 1) {
X_dummy_with_na[r, c] <- NA
}
}
}
# Dummy binary outcome (y)
# Let y depend on feat1 and feat2 (when observed)
y_dummy <- as.numeric(X_dummy$feat1 + X_dummy$feat2 + rnorm(n, 0, 0.5) > 0)
cat("Dummy data created:\n")
cat("  X (with NAs) dimensions:", dim(X_dummy_with_na), "\n")
cat("  M (mask) dimensions:", dim(M_dummy), "\n")
cat("  y (outcome) length:", length(y_dummy), "\n")
cat("\nSample of X (with NAs) and M:\n")
print(head(cbind(X_dummy_with_na, M_dummy)))
cat("\nInstantiating and training RegLogPatByPat method...\n")
# Create an instance of your Pattern-by-Pattern method
pbp_method <- RegLogPatByPat$new(name = "MyPbPMethod")
# Fit the model using the dummy data
# This will train a separate glm for each unique pattern
fit_success <- pbp_method$fit(X = X_dummy_with_na, M = M_dummy, y = y_dummy)
y_dummy
if (fit_success) {
cat("RegLogPatByPat fit successfully.\n")
cat("Number of models trained for unique patterns:", length(pbp_method$models_by_pattern), "\n")
# You can inspect the stored models:
# names(pbp_method$models_by_pattern)
# summary(pbp_method$models_by_pattern[["0_0_0"]]) # Example: for the all-observed pattern
} else {
cat("RegLogPatByPat fitting failed.\n")
}
cat("\nDemonstrating prediction...\n")
# Create some new dummy data for prediction
X_new_dummy <- data.frame(
feat1 = c(0.5, -1.0, 1.5, -0.5, 0.2),
feat2 = c(0.1, 0.8, -0.2, NA, NA), # Some NAs here
feat3 = c(-0.3, NA, 0.7, 0.4, NA)  # Some NAs here
)
# Create corresponding mask for new data
M_new_dummy <- matrix(0, nrow = nrow(X_new_dummy), ncol = ncol(X_new_dummy))
M_new_dummy[is.na(X_new_dummy)] <- 1 # Set 1 for NA, 0 for observed
cat("New data for prediction:\n")
print(X_new_dummy)
cat("\nNew data mask:\n")
print(M_new_dummy)
# Predict probabilities using the trained method
predicted_probs <- pbp_method$predict_probs(X_new = X_new_dummy, M_new = M_new_dummy)
cat("\nPredicted probabilities for new data:\n")
print(predicted_probs)
cat("\nScript finished successfully.\n")
# Now, source your actual methods file:
source("methods_in_R.R")
# Please ensure the path is correct or place this script in the same directory.
# ---
# 2. Create dummy data
# ---
cat("Creating dummy data...\n")
n<-500
# Dummy features (X)
set.seed(123) # for reproducibility
X_dummy <- data.frame(
feat1 = rnorm(n),
feat2 = rnorm(n),
feat3 = rnorm(n)
)
# Dummy missingness mask (M)
# 0 = observed, 1 = missing (as per your Python example)
M_dummy <- matrix(0, nrow = n, ncol = 3)
# Introduce some missing patterns:
# Pattern 1: All observed (0_0_0) - should be 70% of data
# Pattern 2: feat2 missing (0_1_0) - should be 20% of data
M_dummy[1, 2] <- 1
# Pattern 3: feat1 and feat3 missing (1_0_1) - should be 10% of data
M_dummy[2, 1] <- 1
M_dummy[3, 3] <- 1
# Create NAs in X based on M
X_dummy_with_na <- X_dummy
for (r in 1:nrow(M_dummy)) {
for (c in 1:ncol(M_dummy)) {
if (M_dummy[r, c] == 1) {
X_dummy_with_na[r, c] <- NA
}
}
}
# Dummy binary outcome (y)
# Let y depend on feat1 and feat2 (when observed)
y_dummy <- as.numeric(X_dummy$feat1 + X_dummy$feat2 + rnorm(n, 0, 0.5) > 0)
cat("Dummy data created:\n")
cat("  X (with NAs) dimensions:", dim(X_dummy_with_na), "\n")
cat("  M (mask) dimensions:", dim(M_dummy), "\n")
cat("  y (outcome) length:", length(y_dummy), "\n")
cat("\nSample of X (with NAs) and M:\n")
print(head(cbind(X_dummy_with_na, M_dummy)))
# ---
# 3. Instantiate and train RegLogPatByPat
# ---
cat("\nInstantiating and training RegLogPatByPat method...\n")
# Create an instance of your Pattern-by-Pattern method
pbp_method <- RegLogPatByPat$new(name = "MyPbPMethod")
# Fit the model using the dummy data
# This will train a separate glm for each unique pattern
fit_success <- pbp_method$fit(X = X_dummy_with_na, M = M_dummy, y = y_dummy)
if (fit_success) {
cat("RegLogPatByPat fit successfully.\n")
cat("Number of models trained for unique patterns:", length(pbp_method$models_by_pattern), "\n")
# You can inspect the stored models:
# names(pbp_method$models_by_pattern)
# summary(pbp_method$models_by_pattern[["0_0_0"]]) # Example: for the all-observed pattern
} else {
cat("RegLogPatByPat fitting failed.\n")
}
# ---
# 4. Demonstrate prediction
# ---
cat("\nDemonstrating prediction...\n")
# Create some new dummy data for prediction
X_new_dummy <- data.frame(
feat1 = c(0.5, -1.0, 1.5, -0.5, 0.2),
feat2 = c(0.1, 0.8, -0.2, NA, NA), # Some NAs here
feat3 = c(-0.3, NA, 0.7, 0.4, NA)  # Some NAs here
)
# Create corresponding mask for new data
M_new_dummy <- matrix(0, nrow = nrow(X_new_dummy), ncol = ncol(X_new_dummy))
M_new_dummy[is.na(X_new_dummy)] <- 1 # Set 1 for NA, 0 for observed
cat("New data for prediction:\n")
print(X_new_dummy)
cat("\nNew data mask:\n")
print(M_new_dummy)
# Predict probabilities using the trained method
predicted_probs <- pbp_method$predict_probs(X_new = X_new_dummy, M_new = M_new_dummy)
cat("\nPredicted probabilities for new data:\n")
print(predicted_probs)
cat("\nScript finished successfully.\n")
source("methods_in_R.R")
cat("--- Creating Dummy Data ---\n")
set.seed(42) # For reproducibility
# Scenario 1: Enough complete cases to train a model
X_scenario1 <- data.frame(
feat1 = rnorm(50),
feat2 = rnorm(50),
feat3 = rnorm(50)
)
M_scenario1 <- matrix(0, nrow = 50, ncol = 3)
# Introduce some missingness, but ensure plenty of complete cases
M_scenario1[sample(1:50, 10), 1] <- 1 # 10 NAs in feat1
M_scenario1[sample(1:50, 10), 2] <- 1 # 10 NAs in feat2
y_scenario1 <- as.numeric(X_scenario1$feat1 + X_scenario1$feat2 + rnorm(50, 0, 0.5) > 0)
# Scenario 2: Not enough complete cases OR only one class in complete cases
X_scenario2 <- data.frame(
feat1 = rnorm(20),
feat2 = rnorm(20),
feat3 = rnorm(20)
)
M_scenario2 <- matrix(1, nrow = 20, ncol = 3) # Almost all missing
M_scenario2[1:2, ] <- 0 # Only 2 complete cases (not enough for two classes)
M_scenario2[3:5, 1] <- 0 # A few partial cases
y_scenario2 <- rep(0, 20) # All outcomes are 0
# Adjust y for scenario 2 to ensure only one class in complete cases
# The first two cases are complete:
y_scenario2[1:2] <- 0 # Both complete cases have y=0
y_scenario2[3:20] <- sample(c(0,1), 18, replace = TRUE) # Other cases can be mixed
cat("\n--- Testing Scenario 1: Sufficient Complete Cases ---\n")
cat(" (Expected: Model trained, predictions from GLM)\n")
cc_model1 <- CompleteCase$new(name = "CC_Test1")
cc_model1$fit(X = X_scenario1, M = M_scenario1, y = y_scenario1)
X_scenario1
M_scenario1
X_scenario1
source("methods_in_R.R")
---
## Creating Dummy Data
Here's the corrected dummy data generation. I've added a loop to set values in `X` to `NA` based on the `M` (mask) matrices.
set.seed(42) # For reproducibility
# Helper function to introduce NAs based on a mask
introduce_na_from_mask <- function(X_df, M_matrix) {
X_with_na <- X_df
for (r in 1:nrow(M_matrix)) {
for (c in 1:ncol(M_matrix)) {
if (M_matrix[r, c] == 1) { # If mask indicates missing (1)
X_with_na[r, c] <- NA
}
}
}
return(X_with_na)
}
# Scenario 1: Enough complete cases to train a model
cat("--- Scenario 1: Sufficient Complete Cases ---\n")
X_base1 <- data.frame(
feat1 = rnorm(50),
feat2 = rnorm(50),
feat3 = rnorm(50)
)
M_scenario1 <- matrix(0, nrow = 50, ncol = 3)
# Introduce some missingness (e.g., 10 NAs in feat1, 10 NAs in feat2)
M_scenario1[sample(1:50, 10), 1] <- 1
M_scenario1[sample(1:50, 10), 2] <- 1
# Now, apply the missingness to X_base1
X_scenario1 <- introduce_na_from_mask(X_base1, M_scenario1)
y_scenario1 <- as.numeric(X_base1$feat1 + X_base1$feat2 + rnorm(50, 0, 0.5) > 0)
cat("  X_scenario1 head (with NAs):\n")
print(head(X_scenario1))
cat("  M_scenario1 head:\n")
print(head(M_scenario1))
# Scenario 2: Not enough complete cases OR only one class in complete cases
cat("\n--- Scenario 2: Insufficient Complete Cases / Only One Class ---\n")
X_base2 <- data.frame(
feat1 = rnorm(20),
feat2 = rnorm(20),
feat3 = rnorm(20)
)
M_scenario2 <- matrix(1, nrow = 20, ncol = 3) # Make most values missing (1)
# Ensure only 2 complete cases (not enough for 2 classes of y, potentially)
M_scenario2[1:2, ] <- 0
M_scenario2[3:5, 1] <- 0 # A few partial cases (not complete)
# Apply the missingness to X_base2
X_scenario2 <- introduce_na_from_mask(X_base2, M_scenario2)
# Set y such that only one class appears in the complete cases (y[1:2])
y_scenario2 <- rep(0, 20) # All outcomes are 0 for complete cases
y_scenario2[3:20] <- sample(c(0,1), 18, replace = TRUE) # Other cases can be mixed
cat("  X_scenario2 head (with NAs):\n")
print(head(X_scenario2))
cat("  M_scenario2 head:\n")
print(head(M_scenario2))
---
## Test Scenario 1: Sufficient Complete Cases
In this scenario, we expect the `CompleteCase` model to **train successfully** and provide predictions based on the fitted logistic regression.
cat("\n--- Testing Scenario 1: Sufficient Complete Cases ---\n")
cat(" (Expected: Model trained, predictions from GLM)\n")
cc_model1 <- CompleteCase$new(name = "CC_Test1")
cc_model1$fit(X = X_scenario1, M = M_scenario1, y = y_scenario1)
# Check predictions
X_test1 <- data.frame(feat1=c(0.1, 0.5), feat2=c(-0.2, 0.8), feat3=c(0.3, 0.0))
M_test1 <- matrix(0, nrow=2, ncol=3) # Assume these new test cases are complete
cat("\nPredictions (Scenario 1):\n")
cat("Probabilities: ", cc_model1$predict_probs(X_test1, M_test1), "\n")
cat("Classes:       ", cc_model1$predict(X_test1, M_test1), "\n")
X_test1
M_test1
cat("\nPredictions (Scenario 1):\n")
cat("Probabilities: ", cc_model1$predict_probs(X_test1, M_test1), "\n")
cat("Classes:       ", cc_model1$predict(X_test1, M_test1), "\n")
cat("\nModel Parameters (Scenario 1):\n")
params1 <- cc_model1$return_params()
if (!is.null(params1)) {
cat("Coefficients: ", params1[[1]], "\n")
cat("Intercept:    ", params1[[2]], "\n")
} else {
cat("No parameters returned (model not trained).\n")
}
params1 <- cc_model2$return_params()
