{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"ExpB\"\n",
    "\n",
    "df_set_up = pd.read_csv(os.path.join(\"data\",exp,\"set_up.csv\"))\n",
    "df_simulations = pd.read_csv(os.path.join(\"data\",exp,\"simulation.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there some cols of set_up not in simulations\n",
    "if not np.all([df_set_up.columns[i] in df_simulations.columns for i in range(len(df_set_up.columns))]):\n",
    "    df_simulations_enlarged = pd.merge(left=df_simulations, right=df_set_up, on=\"set_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def deal_with_estimated_beta(beta_str, method, d=5):\n",
    "\n",
    "    if type(beta_str) != str:\n",
    "        return None\n",
    "\n",
    "    beta_list = ast.literal_eval(beta_str)\n",
    "\n",
    "    if len(beta_list[0]) == d:\n",
    "        return beta_list[0]\n",
    "    \n",
    "    if len(beta_list[0]) == 2*d:\n",
    "        return beta_list[0][:d]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"The length of beta_list is not 5 or 10 -- Method {method}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulations_enlarged[\"pred_beta\"] = df_simulations_enlarged.apply(lambda x: deal_with_estimated_beta(x[\"estimated_beta\"], x[\"method\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_simulations_enlarged.to_csv(os.path.join(\"data\",exp,\"simulation_set_up.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Remove index col from simulation.csv ##\n",
    "##########################################\n",
    "\n",
    "# df_simulations = pd.read_csv(os.path.join(\"data\",exp,\"simulation.csv\"))\n",
    "# df_simulations.drop(df_simulations.columns[[0]], axis=1, inplace=True)\n",
    "# print(df_simulations.head())\n",
    "# df_simulations.to_csv(os.path.join(\"data\",exp,\"simulation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_500\n",
      "361..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_500\n",
      "362..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_500\n",
      "363..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_500\n",
      "364..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_500\n",
      "365..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_500\n",
      "366..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_1000\n",
      "367..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_1000\n",
      "368..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_500\n",
      "369..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_500\n",
      "370..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_1000\n",
      "371..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_1000\n",
      "372..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_5000\n",
      "373..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_5000\n",
      "374..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.M.IMP_10000\n",
      "375..Deleted LOG_n25000_d5_corr033_prcNA035_cent02_rep0_MICE.Y.IMP_10000\n",
      "376..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.M.IMP_500\n",
      "377..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.Y.IMP_500\n",
      "378..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.M.IMP_1000\n",
      "379..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.Y.IMP_1000\n",
      "380..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.M.IMP_5000\n",
      "381..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.Y.IMP_5000\n",
      "382..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.M.IMP_10000\n",
      "383..Deleted LOG_n25000_d5_corr033_prcNA035_cent035_rep0_MICE.Y.IMP_10000\n",
      "384..Deleted LOG_n25000_d5_corr033_prcNA035_cent085_rep0_MICE.M.IMP_500\n",
      "385..Deleted LOG_n25000_d5_corr033_prcNA035_cent085_rep0_MICE.Y.IMP_500\n",
      "386..Deleted LOG_n25000_d5_corr033_prcNA035_cent085_rep0_MICE.M.IMP_1000\n",
      "387..Deleted LOG_n25000_d5_corr033_prcNA035_cent085_rep0_MICE.Y.IMP_1000\n",
      "388..Deleted LOG_n25000_d5_corr033_prcNA035_cent085_rep0_MICE.M.IMP_5000\n",
      "389..Deleted LOG_n25000_d5_corr033_prcNA035_cent085_rep0_MICE.Y.IMP_5000\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## Remove some results ##\n",
    "#########################\n",
    "\n",
    "method = [\"MICE.5.IMP\", \"MICE.IMP\", \"MICE.M.IMP\", \"MICE.Y.IMP\", \"MICE.IMP.Y.M.IMP\", \"SAEM\", \"MICE.Y.M.IMP\"]\n",
    "n_train = None\n",
    "exp = \"ExpB\"\n",
    "\n",
    "\n",
    "def filter_simulations(method, n_train, exp):\n",
    "\n",
    "    df_simulations_temp = pd.read_csv(os.path.join(\"data\",exp,\"simulation.csv\"))\n",
    "    df_simulations_copy = df_simulations_temp.copy()\n",
    "    all_n_train = df_simulations_temp[\"n_train\"].unique()\n",
    "    if n_train is None:\n",
    "        n_train = all_n_train\n",
    "\n",
    "    df_simulations_temp = df_simulations_temp[df_simulations_temp[\"n_train\"].isin(n_train)]\n",
    "    df_simulations_temp = df_simulations_temp[df_simulations_temp[\"method\"].isin(method)]\n",
    "\n",
    "    for i, row in df_simulations_temp.iterrows():\n",
    "        file_name = row[\"file_name\"]\n",
    "\n",
    "        # delete the file\n",
    "        if os.path.exists(os.path.join(\"data\",exp,\"pred_data\", f\"{file_name}.npz\")):\n",
    "            os.remove(os.path.join(\"data\",exp,\"pred_data\", f\"{file_name}.npz\"))\n",
    "\n",
    "        # delete row in the dataframe\n",
    "        df_simulations_copy = df_simulations_copy.drop(i)\n",
    "\n",
    "        print(f\"{i}..Deleted {file_name}\")\n",
    "\n",
    "    df_simulations_copy.to_csv(os.path.join(\"data\",exp,\"simulation.csv\"), index=False)\n",
    "    # print(df_simulations_copy)\n",
    "\n",
    "# filter_simulations(method, n_train, exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
